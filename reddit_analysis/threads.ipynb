{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Reddit Data from Ethereum, Bitcoin, and Ethereum Classic Subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CSV file output from Scrapy into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Open CSV files from Scrapy output\n",
    "\n",
    "threads_eth = pd.read_csv('redditData/threads_eth_fix.csv')\n",
    "threads_btc = pd.read_csv('redditData/threads_btc_fix.csv')\n",
    "threads_etc = pd.read_csv('redditData/threads_etc_fix.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you need to parse comments to int\n",
    "# threads_eth['comments'] = threads_eth['comments'].map(lambda x: x.rstrip(' comments'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysis of Reddit Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Graph of author posts for Ethereum\n",
    "\n",
    "eth_author = threads_eth.author\n",
    "eth_author_bar = eth_author.value_counts().head(25).plot(kind='bar')\n",
    "eth_author_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Graph of author posts for Bitcoin\n",
    "\n",
    "btc_author = threads_btc.author\n",
    "btc_author_bar = btc_author.value_counts().head(25).plot(kind='bar')\n",
    "btc_author_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Graph of author posts for Ethereum Classic\n",
    "\n",
    "etc_author = threads_etc.author\n",
    "etc_author_bar = etc_author.value_counts().head(25).plot(kind='bar')\n",
    "etc_author_bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments per author in ETH, BTC, or ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comments from Ethereum with authors\n",
    "eth_comments = threads_eth[['author', 'comments']].copy()\n",
    "\n",
    "# Highest number of comments on unique post by author\n",
    "eth_comments.sort_values(by='comments', ascending=False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total number of comments received by author for all author's posts\n",
    "\n",
    "eth_comment_tot = eth_comments.groupby('author').sum()\n",
    "eth_comment_tot_sort = eth_comment_tot.sort_values(by='comments', ascending=False).head(30).plot(kind='bar')\n",
    "eth_comment_tot_sort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comments from Bitcoin with authors\n",
    "btc_comments = threads_btc[['author', 'comments']].copy()\n",
    "\n",
    "# Highest number of comments on unique post by author\n",
    "btc_comments.sort_values(by='comments', ascending=False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total number of comments received by author for all author's posts\n",
    "\n",
    "btc_comment_tot = btc_comments.groupby('author').sum()\n",
    "btc_comment_tot_sort = btc_comment_tot.sort_values(by='comments', ascending=False).head(30).plot(kind='bar')\n",
    "btc_comment_tot_sort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comments from Ethereum Classic with authors\n",
    "etc_comments = threads_etc[['author', 'comments']].copy()\n",
    "\n",
    "# Highest number of comments on unique post by author\n",
    "etc_comments.sort_values(by='comments', ascending=False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total number of comments received by author for all author's posts\n",
    "\n",
    "etc_comment_tot = etc_comments.groupby('author').sum()\n",
    "etc_comment_tot_sort = etc_comment_tot.sort_values(by='comments', ascending=False).head(30).plot(kind='bar')\n",
    "etc_comment_tot_sort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors that are found in ETH, BTC, and ETC forums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the above Series into DataFrames\n",
    "\n",
    "df_eth = pd.Series.to_frame(eth_author.drop_duplicates(keep='first'))\n",
    "df_btc = pd.Series.to_frame(btc_author.drop_duplicates(keep='first'))\n",
    "df_etc = pd.Series.to_frame(etc_author.drop_duplicates(keep='first'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count of unique authors in forums\n",
    "\n",
    "unique_author = pd.DataFrame({'ETH': [len(df_eth)], 'BTC': [len(df_btc)], 'ETC': [len(df_etc)]}).plot(kind='bar')\n",
    "unique_author\n",
    "print('BTC:', len(df_btc), 'ETC:', len(df_etc), 'ETH:',len(df_eth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with all authors\n",
    "\n",
    "df_authors = pd.DataFrame({}, columns=('btc', 'eth', 'etc'))\n",
    "df_authors.btc = df_btc.author\n",
    "df_authors.eth = df_eth.author\n",
    "df_authors.etc = df_etc.author\n",
    "# df_authors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count of which posts in one forum have been created by unique authors from another forum\n",
    "\n",
    "btc_in_eth = Counter(df_authors.btc.dropna().isin(eth_author) == True)\n",
    "btc_in_etc = Counter(df_authors.btc.dropna().isin(etc_author) == True)\n",
    "eth_in_etc = Counter(df_authors.eth.dropna().isin(etc_author) == True)\n",
    "eth_in_btc = Counter(df_authors.eth.dropna().isin(btc_author) == True)\n",
    "etc_in_btc = Counter(df_authors.etc.dropna().isin(btc_author) == True)\n",
    "etc_in_eth = Counter(df_authors.etc.dropna().isin(eth_author) == True)\n",
    "\n",
    "multiple_author = pd.DataFrame({'BTC in ETH': [btc_in_eth[True]], 'BTC in ETC': [btc_in_etc[True]], 'ETH in BTC': [eth_in_btc[True]], 'ETH in ETC': [eth_in_etc[True]], 'ETC in BTC': [etc_in_btc[True]], 'ETC in ETH': [etc_in_eth[True]]})\n",
    "ma_graph = multiple_author.plot(kind='bar')\n",
    "ma_graph.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Table for above graph\n",
    "\n",
    "multiple_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Author names from Bitcoin subreddit who posted in Ethereum subreddit\n",
    "\n",
    "authors_btc_in_eth = df_authors[df_authors.btc.isin(df_authors.eth)]\n",
    "authors_btc_in_eth = authors_btc_in_eth.btc\n",
    "authors_btc_in_eth = authors_btc_in_eth.dropna()\n",
    "\n",
    "# Author names from Ethereum subreddit who posted in Bitcoin subreddit\n",
    "\n",
    "authors_eth_in_btc = df_authors[df_authors.eth.isin(df_authors.btc)]\n",
    "authors_eth_in_btc = authors_eth_in_btc.eth\n",
    "authors_eth_in_btc = authors_eth_in_btc.dropna()\n",
    "\n",
    "# Author names from Bitcoin subreddit who posted in Ethereum Classic subreddit\n",
    "\n",
    "authors_btc_in_etc = df_authors[df_authors.btc.isin(df_authors.etc)]\n",
    "authors_btc_in_etc = authors_btc_in_etc.btc\n",
    "authors_btc_in_etc = authors_btc_in_etc.dropna()\n",
    "\n",
    "# Author names from Ethereum Classic subreddit who posted in Bitcoin subreddit\n",
    "\n",
    "authors_etc_in_btc = df_authors[df_authors.etc.isin(df_authors.btc)]\n",
    "authors_etc_in_btc = authors_etc_in_btc.etc\n",
    "authors_etc_in_btc = authors_etc_in_btc.dropna()\n",
    "\n",
    "# Author names from Ethereum subreddit who posted in Ethereum Classic subreddit\n",
    "\n",
    "authors_eth_in_etc = df_authors[df_authors.eth.isin(df_authors.etc)]\n",
    "authors_eth_in_etc = authors_eth_in_etc.eth\n",
    "authors_eth_in_etc = authors_eth_in_etc.dropna()\n",
    "\n",
    "# Author names from Ethereum Classic subreddit who posted in Ethereum subreddit\n",
    "\n",
    "authors_etc_in_eth = df_authors[df_authors.etc.isin(df_authors.eth)]\n",
    "authors_etc_in_eth = authors_etc_in_eth.etc\n",
    "authors_etc_in_eth = authors_etc_in_eth.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# authors_btc_in_eth\n",
    "# authors_eth_in_btc\n",
    "# authors_btc_in_etc\n",
    "# authors_etc_in_btc\n",
    "# authors_eth_in_etc\n",
    "# authors_etc_in_eth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a simple count of author's number of posts from the perspectives of the above results\n",
    "\n",
    "all_authors_names = list(authors_btc_in_etc) + list(authors_btc_in_eth) + list(authors_etc_in_btc) + list(authors_etc_in_eth) + list(authors_eth_in_btc) + list(authors_eth_in_etc)\n",
    "all_authors_names_count = Counter(all_authors_names)\n",
    "all_authors_names_count = pd.DataFrame.from_dict(all_authors_names_count, orient='index')\n",
    "# all_authors_names_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table of authors found in one subreddit who have published in another subreddit\n",
    "\n",
    "all_authors_names_pivot = pd.DataFrame({}, columns=('names', 'btc_in_eth', 'eth_in_btc', 'btc_in_etc', 'etc_in_btc', 'eth_in_etc', 'etc_in_eth'))\n",
    "all_authors_names_pivot.names = all_authors_names_count.index.unique()\n",
    "all_authors_names_pivot = all_authors_names_pivot.fillna(value=0)\n",
    "all_authors_names_pivot2 = all_authors_names_pivot.set_index(['names'])\n",
    "\n",
    "# all_authors_names_pivot\n",
    "# all_authors_names_pivot2\n",
    "\n",
    "# Fill pivot2 with '1' for each instancy a unique author from one subreddit was found in another\n",
    "\n",
    "for x in list(all_authors_names_pivot.names):\n",
    "    if (x in list(authors_btc_in_etc)) == True:\n",
    "        all_authors_names_pivot2.ix[x, ['btc_in_etc']] += 1\n",
    "\n",
    "for x in list(all_authors_names_pivot.names):\n",
    "    if (x in list(authors_btc_in_eth)) == True:\n",
    "        all_authors_names_pivot2.ix[x, ['btc_in_eth']] += 1\n",
    "\n",
    "for x in list(all_authors_names_pivot.names):\n",
    "    if (x in list(authors_eth_in_btc)) == True:\n",
    "        all_authors_names_pivot2.ix[x, ['eth_in_btc']] += 1\n",
    "\n",
    "for x in list(all_authors_names_pivot.names):\n",
    "    if (x in list(authors_eth_in_etc)) == True:\n",
    "        all_authors_names_pivot2.ix[x, ['eth_in_etc']] += 1\n",
    "\n",
    "for x in list(all_authors_names_pivot.names):\n",
    "    if (x in list(authors_etc_in_btc)) == True:\n",
    "        all_authors_names_pivot2.ix[x, ['etc_in_btc']] += 1\n",
    "\n",
    "for x in list(all_authors_names_pivot.names):\n",
    "    if (x in list(authors_etc_in_eth)) == True:\n",
    "        all_authors_names_pivot2.ix[x, ['etc_in_eth']] += 1\n",
    "\n",
    "# Style the '1' values green within DataFrame output\n",
    "\n",
    "all_authors_names_pivot2.style.highlight_max(color='green')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analysis of forums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Posts within General Reddit Timeframes - Date of Information (DOI): 26 December 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input for this funtion is DataFrame with column 'time_rel' from the Reddit scrape\n",
    "\n",
    "def posttime_rel(threads):\n",
    "    rel_time = threads.time_rel.value_counts()\n",
    "    rel_time.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posttime_rel(threads_eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "posttime_rel(threads_btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "posttime_rel(threads_etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posts per month over all records (as of DOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input for this funtion is DataFrame with column 'mon' from the Reddit scrape\n",
    "\n",
    "def time_month_all(threads):\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    month_dict = dict(threads.mon.value_counts())\n",
    "    month_count = pd.DataFrame.from_dict(data=month_dict, orient='index')\n",
    "    month_count = month_count.rename(columns={'': 'mon', 0: 'count'})\n",
    "    month_count = month_count.reindex(months)\n",
    "    month_count.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_month_all(threads_eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_month_all(threads_btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_month_all(threads_etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posts per year over all records (as of DOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input for this funtion is DataFrame with column 'year' from the Reddit scrape\n",
    "\n",
    "def time_year_all(threads):\n",
    "    years = [2013, 2014, 2015, 2016]\n",
    "    year_dict = dict(threads.year.value_counts())\n",
    "    year_count = pd.DataFrame.from_dict(data=year_dict, orient='index')\n",
    "    year_count = year_count.rename(columns={'': 'year', 0: 'count'})\n",
    "    year_count = year_count.reindex(years)\n",
    "    year_count.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_year_all(threads_eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_year_all(threads_btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_year_all(threads_etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post per day of the week over all records (as of DOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input for this funtion is DataFrame with column 'dow' from the Reddit scrape\n",
    "\n",
    "def time_dow_all(threads):\n",
    "    dows = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "    dow_dict = dict(threads.dow.value_counts())\n",
    "    dow_count = pd.DataFrame.from_dict(data=dow_dict, orient='index')\n",
    "    dow_count = dow_count.rename(columns={'': 'dow', 0: 'count'})\n",
    "    dow_count = dow_count.reindex(dows)\n",
    "    dow_count.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_dow_all(threads_eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_dow_all(threads_btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_dow_all(threads_etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posts per day of the month over all records (as of DOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input for this funtion is DataFrame with column 'day' from the Reddit scrape\n",
    "\n",
    "def time_day_all(threads):\n",
    "    days = list(range(1,32,1))\n",
    "    day_dict = dict(threads.day.value_counts())\n",
    "    day_count = pd.DataFrame.from_dict(data=day_dict, orient='index')\n",
    "    day_count = day_count.rename(columns={'': 'day', 0: 'count'})\n",
    "    day_count = day_count.reindex(days)\n",
    "    day_count.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_day_all(threads_eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_day_all(threads_btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_day_all(threads_etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Title Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create text files for wordclouds\n",
    "\n",
    "with open('redditData/threads_eth.txt', 'w') as eth_f:\n",
    "    for line in threads_eth['title']:\n",
    "        eth_f.write(line)\n",
    "\n",
    "with open('redditData/threads_btc.txt', 'w') as btc_f:\n",
    "    for line in threads_btc['title']:\n",
    "        btc_f.write(line)\n",
    "\n",
    "with open('redditData/threads_etc.txt', 'w') as etc_f:\n",
    "    for line in threads_etc['title']:\n",
    "        etc_f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wordcloud generator function for raw files\n",
    "\n",
    "def wcg(file):\n",
    "    text = open(file).read()\n",
    "    text.lower()\n",
    "    wc = WordCloud(background_color='black')\n",
    "    wc.generate(text)\n",
    "    wc.to_file('%s.jpg' % file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# JPG wordcloud files\n",
    "\n",
    "wcg('redditData/threads_eth.txt')\n",
    "wcg('redditData/threads_btc.txt')\n",
    "wcg('redditData/threads_etc.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ETH](images/threads_eth.txt.jpg)\n",
    "[BTC](images/threads_btc.txt.jpg)\n",
    "[ETC](images/threads_etc.txt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Word frequency tables for ETH, BTC, and ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stop word list\n",
    "\n",
    "stopwords = ['-', '&', ',', ':', ';', '.', ',', 'a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'did', 'do', 'done', 'down', 'due', 'during', 'each', 'eg', 'either', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fill', 'find', 'for', 'former', 'formerly', 'found', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on','once', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'take', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word frequency table for Ethereum\n",
    "\n",
    "with open('redditData/threads_eth.txt', 'r') as eth_f:\n",
    "    words_eth = eth_f.read()\n",
    "    wordlist_eth = words_eth.lower().split()\n",
    "    wordcount_eth = Counter(wordlist_eth)\n",
    "    wordcount_eth2 = pd.DataFrame.from_dict(wordcount_eth, orient='index').reset_index()\n",
    "    wordcount_eth2 = wordcount_eth2.rename(columns={'index':'word', 0:'count'})\n",
    "    \n",
    "wordcount_eth2[wordcount_eth2['word'].map(lambda x: x not in stopwords)].sort_values('count', ascending=False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word frequency table for Bitcoin\n",
    "\n",
    "with open('redditData/threads_btc.txt', 'r') as btc_f:\n",
    "    words_btc = btc_f.read()\n",
    "    wordlist_btc = words_btc.lower().split()\n",
    "    wordcount_btc = Counter(wordlist_btc)\n",
    "    wordcount_btc2 = pd.DataFrame.from_dict(wordcount_btc, orient='index').reset_index()\n",
    "    wordcount_btc2 = wordcount_btc2.rename(columns={'index':'word', 0:'count'})\n",
    "    \n",
    "wordcount_btc2[wordcount_btc2['word'].map(lambda x: x not in stopwords)].sort_values('count', ascending=False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word frequency table for Ethereum Classic\n",
    "\n",
    "with open('redditData/threads_etc.txt', 'r') as etc_f:\n",
    "    words_etc = etc_f.read()\n",
    "    wordlist_etc = words_etc.lower().split()\n",
    "    wordcount_etc = Counter(wordlist_etc)\n",
    "    wordcount_etc2 = pd.DataFrame.from_dict(wordcount_etc, orient='index').reset_index()\n",
    "    wordcount_etc2 = wordcount_etc2.rename(columns={'index':'word', 0:'count'})\n",
    "    \n",
    "wordcount_etc2[wordcount_etc2['word'].map(lambda x: x not in stopwords)].sort_values('count', ascending=False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
